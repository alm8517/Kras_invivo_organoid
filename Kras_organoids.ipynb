{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline to reproduce 7 day organoid data \n",
    "\n",
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import magic\n",
    "import matplotlib.colors\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import colors\n",
    "import seaborn as sb\n",
    "from gprofiler import gprofiler\n",
    "from seaborn import despine\n",
    "from seaborn import axes_style\n",
    "from matplotlib.pyplot import suptitle\n",
    "\n",
    "sc.settings.verbosity = 3             # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_versions()\n",
    "sc.settings.set_figure_params(dpi=80)\n",
    "results_file = 'organoids_KY.h5ad'  # the file that will store the analysis results\n",
    "\n",
    "#load and merge files\n",
    "\n",
    "filenames=['KY_empty_filtered_feature_bc_matrix.h5','KY_cre_filtered_feature_bc_matrix.h5']\n",
    "\n",
    "adatas=[sc.read_10x_h5(filename) for filename in filenames]\n",
    "\n",
    "adata=adatas[0].concatenate(adatas[1:],batch_categories=[\"KY Empty\",\"KY Cre\"])\n",
    "\n",
    "adata.var_names_make_unique()  # this is unnecessary if using 'gene_ids'\n",
    "\n",
    "# compute %mito and remove cells with >10% followed by normalization, logging and MAGIC\n",
    "mito_genes = adata.var_names.str.startswith('mt-')\n",
    "# for each cell compute fraction of counts in mito genes vs. all genes\n",
    "# the `.A1` is only necessary as X is sparse (to transform to a dense array after summing)\n",
    "adata.obs['percent_mito'] = np.sum(adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1\n",
    "# add the total counts per cell as observations-annotation to adata\n",
    "adata.obs['n_counts'] = adata.X.sum(axis=1).A1\n",
    "\n",
    "# plot mito vs count data before filtering\n",
    "sc.settings.set_figure_params(dpi=80)\n",
    "with axes_style({'axes.grid': False}):\n",
    " sc.pl.scatter(adata, y='percent_mito', x='n_counts', size=5)\n",
    "\n",
    "# filtering\n",
    "adata = adata[adata.obs['percent_mito'] < 0.1, :]\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "# plot mito vs count data after filtering\n",
    "sc.settings.set_figure_params(dpi=80)\n",
    "with axes_style({'axes.grid': False}):\n",
    " sc.pl.scatter(adata, y='percent_mito', x='n_counts', size=5)\n",
    "\n",
    "sc.pp.normalize_per_cell(adata)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "# No consensus about gene scaling so I did not scale the data. Read https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6582955/\n",
    "# Not scaling argueably retains biological information\n",
    "# I did not regress cell cycle either. A population of proliferative or non-proliferative cells in this context would be high interesting in my opinion, and is not information\n",
    "# I want to remove!\n",
    "\n",
    "adata.raw = adata # save a raw data file\n",
    "\n",
    "# data diffusion tool is in scanpy.external \n",
    "sce.pp.magic(adata, name_list='all_genes', k=5, t=15, n_pca=20)\n",
    "\n",
    "sc.pp.neighbors(adata, n_neighbors=5, n_pcs=20)\n",
    "sc.tl.louvain(adata, resolution=0.025, key_added='louvain_r0.025')\n",
    "sc.tl.louvain(adata, resolution=0.05, key_added='louvain_r0.05')\n",
    "sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1')\n",
    "sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2')\n",
    "sc.tl.louvain(adata, resolution=0.3, key_added='louvain_r0.3')\n",
    "sc.tl.louvain(adata, resolution=0.4, key_added='louvain_r0.4')\n",
    "sc.tl.louvain(adata, resolution=0.5, key_added='louvain_r0.5')\n",
    "\n",
    "# create umap\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "# Visualize Louvain resolutions\n",
    "sc.pl.umap(adata, color=['batch','louvain_r0.025','louvain_r0.05','louvain_r0.1','louvain_r0.2','louvain_r0.3','louvain_r0.4','louvain_r0.5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PAGA-initalized UMAP\n",
    "sc.tl.paga(adata, groups='louvain_r0.05')\n",
    "sc.pl.paga(adata, plot=True, color=['batch'])  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "# sc.tl.umap(adata, init_pos='paga') is not working (August 7, 2019)\n",
    "# https://github.com/theislab/scanpy/issues/769 = work around for now..\n",
    "sc.tl.umap(adata, init_pos=sci.tl._utils.get_init_pos_from_paga(adata))\n",
    "\n",
    "# Visualize the data \n",
    "sc.pl.umap(adata, frameon=False, color=['louvain_r0.05'], legend_loc='right margin') # louvain communities\n",
    "sc.pl.umap(adata, frameon=False, color=['batch'], legend_loc='right margin') # batch\n",
    "\n",
    "# Remove small cluster\n",
    "adata.obs['louvain_r0.05'].value_counts() # count the number of cells per cluster\n",
    "adata_subset = adata[adata.obs['louvain_r0.05'].isin(['0','1','2','3','4'])] # Remove clusters with < 50 cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contribution of each library to each Louvain cluster\n",
    "ax = sb.countplot(x=\"louvain_r0.05\", hue=\"batch\", data=adata_subset.obs)\n",
    "plt.xlabel(\"Louvain communities\")\n",
    "plt.ylabel(\"Cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate gene signatures. Principle is true for all gene lists provided in supplementary. Kras score provided as an example\n",
    "bild_kras = pd.read_excel('Supplementary Table 2.xlsx', sheet_name='Bild et al. 2006 (Kras genes)', header=0) # load lists \n",
    "\n",
    "bild_kras_list = bild_kras['GeneSymbol'].tolist() # Make list of gene names\n",
    "\n",
    "# Gene names are capitals. Lower and capitalize to be compatible with dataset gene names\n",
    "\n",
    "bild_kras_list = [x.lower() for x in bild_kras_list] # lower\n",
    "bild_kras_list = [x.capitalize() for x in bild_kras_list] # capitalize\n",
    "\n",
    "bild_kras_list_final = [x for x in bild_kras_list if x in adata.var_names] # remove genes not in adata.var\n",
    "\n",
    "# Calculating z-scores for single cells\n",
    "# Derived from https://github.com/theislab/scanpy/issues/181\n",
    "\n",
    "# Create a cell barcodes column\n",
    "adata_subset.obs['index1'] = adata_subset.obs.index\n",
    "\n",
    "# create the marker dict \n",
    "marker_dict = dict()\n",
    "marker_dict['Kras z-score'] = bild_kras_list_final\n",
    "\n",
    "# create the function\n",
    "def evaluate_partition(anndata, marker_dict, gene_symbol_key=None, partition_key=None):\n",
    "    # Inputs:\n",
    "    #    anndata         - An AnnData object containing the data set and a partition\n",
    "    #    marker_dict     - A dictionary with cell-type markers. The markers should be stores as anndata.var_names or \n",
    "    #                      an anndata.var field with the key given by the gene_symbol_key input\n",
    "    #    gene_symbol_key - The key for the anndata.var field with gene IDs or names that correspond to the marker \n",
    "    #                      genes\n",
    "    #    partition_key   - The key for the anndata.obs field where the cluster IDs are stored. The default is\n",
    "    #                      'louvain_r1' \n",
    "\n",
    "    #Test inputs\n",
    "    if partition_key not in anndata.obs.columns.values:\n",
    "        print('KeyError: The partition key was not found in the passed AnnData object.')\n",
    "        print('   Have you done the clustering? If so, please tell pass the cluster IDs with the AnnData object!')\n",
    "        raise\n",
    "\n",
    "    if (gene_symbol_key != None) and (gene_symbol_key not in anndata.var.columns.values):\n",
    "        print('KeyError: The provided gene symbol key was not found in the passed AnnData object.')\n",
    "        print('   Check that your cell type markers are given in a format that your anndata object knows!')\n",
    "        raise\n",
    "        \n",
    "    if gene_symbol_key:\n",
    "        gene_ids = anndata.var[gene_symbol_key]\n",
    "    else:\n",
    "        gene_ids = anndata.var_names\n",
    "        \n",
    "    # Create a column based on index. This allows z-score calculation on single cells rather than clusters\n",
    "    clusters = np.unique(anndata.obs[partition_key])\n",
    "    n_clust = len(clusters)\n",
    "    n_groups = len(marker_dict)\n",
    "    \n",
    "    marker_res = np.zeros((n_groups, n_clust))\n",
    "    z_scores = sc.pp.scale(anndata, copy=True) # try changing this to anndata_raw as a separate function\n",
    "\n",
    "    i = 0\n",
    "    for group in marker_dict:\n",
    "        # Find the corresponding columns and get their mean expression in the cluster\n",
    "        j = 0\n",
    "        for clust in clusters:\n",
    "            cluster_cells = np.in1d(z_scores.obs[partition_key], clust)\n",
    "            marker_genes = np.in1d(gene_ids, marker_dict[group])\n",
    "            marker_res[i,j] = z_scores.X[np.ix_(cluster_cells,marker_genes)].mean()\n",
    "            j += 1\n",
    "        i+=1\n",
    "\n",
    "    variances = np.nanvar(marker_res, axis=0)\n",
    "    if np.all(np.isnan(variances)):\n",
    "        print(\"No variances could be computed, check if your cell markers are in the data set.\")\n",
    "        print(\"Maybe the cell marker IDs do not correspond to your gene_symbol_key input or the var_names\")\n",
    "        raise\n",
    "\n",
    "    marker_res_df = pd.DataFrame(marker_res, columns=clusters, index=marker_dict.keys())\n",
    "    \n",
    "    return marker_res_df\n",
    "\n",
    "   # Return the median of all the variances over the clusters\n",
    "    #marker_matches = ([np.median(variances), marker_res_df])\n",
    "    \n",
    "   # return marker_matches\n",
    "\n",
    "# Calculate the z-score\n",
    "df = evaluate_partition(adata_subset, marker_dict, gene_symbol_key=None, partition_key = 'index1')\n",
    "\n",
    "# Transpose the dataframe\n",
    "df_transposed = df.transpose()\n",
    "\n",
    "# add score to adata.obs\n",
    "adata_subset.obs['Kras z-score'] = df_transposed['Kras z-score']\n",
    "\n",
    "# save the data after adding the z-score\n",
    "adata_subset.write(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate heatmap using Seaborn\n",
    "\n",
    "d = adata_subset.obs.pivot('louvain_r0.05',\"index1\", \"Kras z-score\")\n",
    "plt.figure(figsize=(5,2))\n",
    "ax = sb.heatmap(d, cmap='RdYlBu_r', xticklabels=False)\n",
    "plt.title('Kras score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann-Whitney test is for independent variables with no distribution assumptions\n",
    "from scipy.stats import mannwhitneyu\n",
    "mannwhitneyu(cat2['Kras score'], cat4['Kras score']) \n",
    "mannwhitneyu(cat2['Kras score'], cat0['Kras score']) \n",
    "mannwhitneyu(cat2['Kras score'], cat1['Kras score']) \n",
    "mannwhitneyu(cat2['Kras score'], cat3['Kras score']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform DE analysis using the in-built ScanPy function\n",
    "sc.tl.rank_genes_groups(adata_subset, 'louvain_r0.05', method='wilcoxon',n_genes=500, use_raw=True)\n",
    "result = adata_subset.uns['rank_genes_groups']\n",
    "groups = result['names'].dtype.names\n",
    "pd.DataFrame({group + '_' + key[:1]: result[key][group] for group in groups for key in ['names', 'pvals_adj','logfoldchanges']}).head(500)\n",
    "\n",
    "# export DE results to excel \n",
    "df1=pd.DataFrame({group + '_' + key[:1]: result[key][group] for group in groups for key in ['names', 'pvals_adj','logfoldchanges']})\n",
    "df1.to_excel(\"organoids_DE_top500.xlsx\", sheet_name='Sheet_name_1')\n",
    "\n",
    "# filtered differential expression for single gene analysis\n",
    "\n",
    "sc.tl.rank_genes_groups(adata_subset, 'louvain_r0.05', method='wilcoxon',n_genes=1000, use_raw=True)\n",
    "\n",
    "sc.tl.filter_rank_genes_groups(adata_subset, \n",
    "    min_fold_change = 1, # minimum log fold change\n",
    "    min_in_group_fraction = 0.5,\n",
    "    max_out_group_fraction = 0.5, \n",
    "  key_added='rank_genes_groups_filtered')\n",
    "\n",
    "result = adata_subset.uns['rank_genes_groups_filtered']\n",
    "groups = result['names'].dtype.names\n",
    "\n",
    "# export DE results to excel \n",
    "df2=pd.DataFrame({group + '_' + key[:1]: result[key][group] for group in groups for key in ['names', 'pvals_adj','logfoldchanges']})\n",
    "df2.to_excel(\"organoids_DE_top1000_filtered.xlsx\", sheet_name='filtered results')\n",
    "\n",
    "sc.tl.rank_genes_groups(adata_subset, 'louvain_r0.05', method='wilcoxon',n_genes=1000, use_raw=True)\n",
    "\n",
    "result = adata_subset.uns['rank_genes_groups']\n",
    "groups = result['names'].dtype.names\n",
    "\n",
    "# export DE results to excel \n",
    "organoids_DE_df=pd.DataFrame({group + '_' + key[:1]: result[key][group] for group in groups for key in ['names', 'pvals_adj','logfoldchanges']})\n",
    "organoids_DE_df.to_excel(\"organoid_DE_top1000_unfiltered.xlsx\", sheet_name='Top 1000 unfiltered')\n",
    "\n",
    "# Visualize filtered results using a heatmap\n",
    "heatmap_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['lightblue','lightyellow','lightcoral'])\n",
    "sc.pl.rank_genes_groups_heatmap(adata_subset, n_genes=25,cmap=heatmap_cmap, swap_axes=True, use_raw=False, key='rank_genes_groups_filtered', vmin=0, vmax=1.5, show_gene_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify TF/TFCs amongst DE genes\n",
    "\n",
    "# import list of mouse TFs from TFDB\n",
    "# http://bioinfo.life.hust.edu.cn/AnimalTFDB/#!/species\n",
    "df_tf = pd.read_excel('Supplementary Table 2.xlsx', sheet_name='TF and TFCs Animal TFDB3', header=0)\n",
    "tf_genes = set(df_tf['Symbol'].tolist())\n",
    "\n",
    "# df2 is filtered DE genes from all the organoid clusters\n",
    "\n",
    "# Find TF/TFCs\n",
    "names = df2.columns # filtered DE results\n",
    "clust_dict = {} #key,value\n",
    "\n",
    "for col in df2.columns:\n",
    "    \n",
    "    # get diff gene list\n",
    "    cluster_genes = df2[col].tolist()\n",
    "\n",
    "    # Create results array\n",
    "    results_tfs = []\n",
    "\n",
    "    # iterate through and pull out common genes\n",
    "    \n",
    "    for i in tf_genes:\n",
    "     if i in cluster_genes:\n",
    "      results_tfs.append(i)\n",
    "    \n",
    "    #store in dict (receptors,ligands,tfs)\n",
    "    the_key = col\n",
    "    the_value = {}\n",
    "    the_value[\"tfs\"] = results_tfs\n",
    "    clust_dict[the_key] = the_value\n",
    "\n",
    "# Create a list of identified TFs\n",
    "merged_tf = []\n",
    "\n",
    "for i in clust_dict:\n",
    "    sub_dict = clust_dict[i] # access each cluster in dict\n",
    "    \n",
    "    # create merge\n",
    "    merged_tf += sub_dict[\"tfs\"]\n",
    "\n",
    "# plot the results using a matrixplot\n",
    "sc.pl.matrixplot(adata_subset, var_names=merged_tf, cmap='viridis', groupby='louvain_r0.05', use_raw=False, swap_axes=True, vmin=0, vmax=0.6, dendrogram=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for enriched Gene Ontology Biological Process 2018 pathways\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina' # mac\n",
    "import gseapy as gp\n",
    "from gseapy.plot import barplot, dotplot\n",
    "\n",
    "#view available reference libraries\n",
    "names = gp.get_library_name()\n",
    "print(names)\n",
    "\n",
    "# turn columns into lists (filtered data)\n",
    "C0 = organoids_DE_df['0_n']\n",
    "C1 = organoids_DE_df['1_n']\n",
    "C2 = organoids_DE_df['2_n']\n",
    "C3 = organoids_DE_df['3_n']\n",
    "C4 = organoids_DE_df['4_n']\n",
    "\n",
    "# drop NaN because they causes Enricher to break\n",
    "C0=C0.dropna()\n",
    "C1=C1.dropna()\n",
    "C2=C2.dropna()\n",
    "C3=C3.dropna()\n",
    "C4=C4.dropna()\n",
    "\n",
    "# GO Analysis\n",
    "Cluster0_GOBio = gp.enrichr(gene_list = C0,\n",
    "description='Cluster0_GOBio',\n",
    "gene_sets=['GO_Biological_Process_2018'],\n",
    "outdir='Enricher_analysis/Cluster0_GOBio',\n",
    "cutoff=0.05\n",
    ")\n",
    "\n",
    "Cluster1_GOBio = gp.enrichr(gene_list = C1,\n",
    "description='Cluster1_GOBio',\n",
    "gene_sets=['GO_Biological_Process_2018'],\n",
    "outdir='Enricher_analysis/Cluster1_GOBio',\n",
    "cutoff=0.05\n",
    ")\n",
    "\n",
    "Cluster2_GOBio = gp.enrichr(gene_list = C2,\n",
    "description='Cluster2_GOBio',\n",
    "gene_sets=['GO_Biological_Process_2018'],\n",
    "outdir='Enricher_analysis/Cluster2_GOBio',\n",
    "cutoff=0.05\n",
    ")\n",
    "\n",
    "Cluster3_GOBio = gp.enrichr(gene_list = C3,\n",
    "description='Cluster3_GOBio',\n",
    "gene_sets=['GO_Biological_Process_2018'],\n",
    "outdir='Enricher_analysis/Cluster3_GOBio',\n",
    "cutoff=0.05\n",
    ")\n",
    "\n",
    "Cluster4_GOBio = gp.enrichr(gene_list = C4,\n",
    "description='Cluster4_GOBio',\n",
    "gene_sets=['GO_Biological_Process_2018'],\n",
    "outdir='Enricher_analysis/Cluster4_GOBio',\n",
    "cutoff=0.05\n",
    ")\n",
    "\n",
    "#  Find unique GO terms\n",
    "\n",
    "# filter for statistically significant terms\n",
    "c0_sig = Cluster0_GOBio.res2d.loc[(Cluster0_GOBio.res2d['Adjusted P-value'] < 0.05)] \n",
    "c1_sig = Cluster1_GOBio.res2d.loc[(Cluster1_GOBio.res2d['Adjusted P-value'] < 0.05)] \n",
    "c2_sig = Cluster2_GOBio.res2d.loc[(Cluster2_GOBio.res2d['Adjusted P-value'] < 0.05)] \n",
    "c3_sig = Cluster3_GOBio.res2d.loc[(Cluster3_GOBio.res2d['Adjusted P-value'] < 0.05)] \n",
    "c4_sig = Cluster4_GOBio.res2d.loc[(Cluster4_GOBio.res2d['Adjusted P-value'] < 0.05)] \n",
    "\n",
    "# create lists\n",
    "c0_list = c0_sig['Term'].tolist() # cancer\n",
    "c1_list = c1_sig['Term'].tolist() # cancer\n",
    "c2_list = c2_sig['Term'].tolist() # wt\n",
    "c3_list = c3_sig['Term'].tolist() # cancer\n",
    "c4_list = c4_sig['Term'].tolist() # wt\n",
    "\n",
    "\n",
    "# find unique GO terms\n",
    "c0_unique_terms = []\n",
    "c1_unique_terms = []\n",
    "c2_unique_terms = []\n",
    "c3_unique_terms = []\n",
    "c4_unique_terms = []\n",
    "common_terms = []\n",
    "\n",
    "for i in c0_list:\n",
    "    if i not in c1_list and i not in c2_list and i not in c3_list and i not in c4_list:\n",
    "        c0_unique_terms.append(i)\n",
    "        \n",
    "for i in c1_list:\n",
    "    if i not in c0_list and i not in c2_list and i not in c3_list and i not in c4_list:\n",
    "        c1_unique_terms.append(i)\n",
    "        \n",
    "for i in c2_list:\n",
    "    if i not in c0_list and i not in c1_list and i not in c3_list and i not in c4_list:\n",
    "        c2_unique_terms.append(i)\n",
    "        \n",
    "for i in c3_list:\n",
    "    if i not in c0_list and i not in c1_list and i not in c2_list and i not in c4_list:\n",
    "        c3_unique_terms.append(i)\n",
    "        \n",
    "for i in c4_list:\n",
    "    if i not in c0_list and i not in c1_list and i not in c2_list and i not in c3_list:\n",
    "        c4_unique_terms.append(i)\n",
    "        \n",
    "# find common GO terms. Note: None were found in my dataset\n",
    "for i in c0_list:\n",
    "    if i in c1_list and i in c2_list and i in c3_list and i in c4_list:\n",
    "        common_terms.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sox9 activation and expression in single cells\n",
    "\n",
    "TTRUST_sox9 = pd.read_excel('Supplementary Table 2.xlsx', sheet_name='Sox9 targets TRRUST', header=0) # load data\n",
    "TTRUST_activation_sox9 = TTRUST_sox9.loc[(TTRUST_sox9['Type'] == 'Activation')] # Extract gene defined as activated\n",
    "TTRUST_activation_sox9_list = TTRUST_activation_sox9['Target'].tolist() # create list\n",
    "TTRUST_activation_sox9_list = [x for x in TTRUST_activation_sox9_list if x in adata.var_names] # remove genes not in adata_var\n",
    "\n",
    "# Calculating z-scores for single cells\n",
    "\n",
    "# create the marker dict \n",
    "marker_dict = dict()\n",
    "marker_dict['Sox9 activation z-score'] = TTRUST_activation_sox9_list\n",
    "\n",
    "# Calculate the z-score\n",
    "# 'evaluate_partition' function was defined earlier\n",
    "df = evaluate_partition(adata_subset, marker_dict, gene_symbol_key=None, partition_key = 'index1')\n",
    "\n",
    "# Transpose the dataframe\n",
    "df_transposed = df.transpose()\n",
    "adata_subset.obs['Sox9_score'] = df_transposed['Sox9 activation z-score']\n",
    "\n",
    "# save the data\n",
    "adata_subset.write(results_file)\n",
    "\n",
    "# add Sox9 expression to adata_subset.obs for TF/activity visualization\n",
    "adata_subset.obs['Sox9']=adata_subset[:, ['Sox9']].to_df()\n",
    "\n",
    "scores = adata_subset.obs[['Klf4_score','Myc_score','Pou5f1_score','Sox2_score','Sox9_score','Sox2','Myc','Pou5f1','Klf4','Sox9']]\n",
    "sox9_phase = pd.Series('No activity', index=scores.index) # default state\n",
    "sox9_phase[(scores.Sox9 > 0) & (scores.Sox9_score < 0)] = 'sox9 expression only'\n",
    "sox9_phase[(scores.Sox9 < 0) & (scores.Sox9_score > 0)] = 'sox9 activity only'\n",
    "sox9_phase[(scores.Sox9 > 0) & (scores.Sox9_score > 0)] = 'sox9 expression + activity'\n",
    "\n",
    "# Add information to adata_subset\n",
    "adata_subset.obs['sox9_phase'] = sox9_phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### You can download the annotated adata_subset file and begin data analysis straight away! ####\n",
    "\n",
    "# load adata_subset file shown in the figures\n",
    "results_file = 'adata_subset.h5ad'  \n",
    "adata_subset = sc.read(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hope you find the data and code useful! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
